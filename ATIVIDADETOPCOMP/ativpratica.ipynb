{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - O que é Aprendizado de Máquina?\n",
    "\n",
    "Aprendizado de máquina é um tipo de algoritmo que pode aprender algo sem instruções. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 - O que caracteriza um problema de classificação?\n",
    "\n",
    "Os problemas de classificação são aqueles onde se busca encontrar uma classe, dentro das possibilidades limitadas existentes.\n",
    "Esta classe pode ser se um aluno foi aprovado ou reprovado, se uma pessoa possui uma doença ou não, dentre outras tantas possibilidades, sendo que nestes casos ou a previsão será uma ou outra.\n",
    "\n",
    "Um algoritmo de classificaão nada mais é do que um passo-a-passo a ser seguido para realizar alguma tarefa específica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 - Diferenças entre SVM e Árvores de Decisão\n",
    "\n",
    "Uma máquina de vetores de suporte (SVM) é um algoritmo de aprendizado de máquina supervisionado que classifica dados encontrando uma linha ou hiperplano ideal que maximize a distância entre cada classe em um espaço n-dimensional.\n",
    "\n",
    "O algoritmo SVM é amplamente usado no aprendizado de máquina, pois é capaz de lidar com tarefas de classificação linear e não linear. No entanto, quando os dados não são linearmente separáveis, as funções kernel são usadas para transformar os dados em um espaço de dimensão superior para permitir a separação linear.\n",
    "\n",
    "Essa aplicação de funções kernel pode ser conhecida como \"truque de kernel\", e a escolha da função kernel, como kernels lineares, kernels polinomiais, kernels de função de base radial (RBF) ou kernels sigmoides, depende das características dos dados e do caso de uso específico.\n",
    "\n",
    "====================================================================================================================\n",
    "\n",
    "As Árvores de Decisão são algoritmos intuitivos que organizam dados hierarquicamente, criando uma estrutura em forma de árvore para facilitar decisões. Cada nó representa uma decisão baseada em atributos dos dados, dividindo-os até um resultado final. Funciona como um fluxograma que guia para a resposta certa. \n",
    "\n",
    "Árvores de decisão são fáceis de entender e lidar com dados variados, captando relações não lineares. Sofrem overfitting em pequenos conjuntos, mas a poda ajuda. Pequenas mudanças nos dados podem afetar a robustez. Usadas em diagnósticos médicos e detecção de fraudes, identificam padrões com eficácia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 - Carregamento e visualização do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0            6      148             72             35        0  33.6   \n",
      "1            1       85             66             29        0  26.6   \n",
      "2            8      183             64              0        0  23.3   \n",
      "3            1       89             66             23       94  28.1   \n",
      "4            0      137             40             35      168  43.1   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                     0.627   50        1  \n",
      "1                     0.351   31        0  \n",
      "2                     0.672   32        1  \n",
      "3                     0.167   21        0  \n",
      "4                     2.288   33        1  \n",
      "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
      "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
      "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
      "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
      "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
      "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
      "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
      "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
      "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
      "\n",
      "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
      "count  768.000000                768.000000  768.000000  768.000000  \n",
      "mean    31.992578                  0.471876   33.240885    0.348958  \n",
      "std      7.884160                  0.331329   11.760232    0.476951  \n",
      "min      0.000000                  0.078000   21.000000    0.000000  \n",
      "25%     27.300000                  0.243750   24.000000    0.000000  \n",
      "50%     32.000000                  0.372500   29.000000    0.000000  \n",
      "75%     36.600000                  0.626250   41.000000    1.000000  \n",
      "max     67.100000                  2.420000   81.000000    1.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('diabetes.csv')\n",
    "\n",
    "print(data.head())\n",
    "\n",
    "print(data.describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 - Divisão em treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do conjunto de treino: (614, 8)\n",
      "Tamanho do conjunto de teste: (154, 8)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.drop('Outcome', axis=1)  \n",
    "y = data['Outcome'] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f'Tamanho do conjunto de treino: {X_train.shape}')\n",
    "print(f'Tamanho do conjunto de teste: {X_test.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 - Normalização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados de treino normalizados:\n",
      "[[-0.52639686 -1.15139792 -3.75268255 -1.32277365 -0.70120553 -4.13525578\n",
      "  -0.49073479 -1.03594038]\n",
      " [ 1.58804586 -0.27664283  0.68034485  0.23350519 -0.70120553 -0.48916881\n",
      "   2.41502991  1.48710085]\n",
      " [-0.82846011  0.56687102 -1.2658623  -0.09071957  0.01344832 -0.42452187\n",
      "   0.54916055 -0.94893896]\n",
      " [-1.13052335  1.2541786  -1.04961706 -1.32277365 -0.70120553 -1.30372015\n",
      "  -0.63929127  2.79212217]\n",
      " [ 0.68185612  0.41066475  0.57222224  1.07648956  2.48460077  1.83812075\n",
      "  -0.68682934  1.13909516]]\n",
      "\n",
      "Dados de teste normalizados:\n",
      "[[ 0.68185612 -0.71402038 -0.61712658  0.81710976  0.93474906  0.26073561\n",
      "  -0.11637247  0.87809089]\n",
      " [-0.52639686 -0.27664283  0.30191569  0.7522648  -0.70120553  0.48053518\n",
      "  -0.954231   -1.03594038]\n",
      " [-0.52639686 -0.40160784 -0.29275872 -1.32277365 -0.70120553 -0.15300476\n",
      "  -0.9245197  -1.03594038]\n",
      " [ 1.28598261 -0.43284909  0.57222224 -1.32277365 -0.70120553 -0.95462672\n",
      "   1.14932872  0.0950781 ]\n",
      " [ 0.98391937  0.47314726  1.11283533 -1.32277365 -0.70120553 -0.26936924\n",
      "  -0.77002097  1.48710085]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Dados de treino normalizados:\")\n",
    "print(X_train_scaled[:5])\n",
    "\n",
    "print(\"\\nDados de teste normalizados:\")\n",
    "print(X_test_scaled[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7 - Treinamento de um modelo SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previsões no conjunto de teste: \n",
      "[0 0 0 0 0 0 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC()\n",
    "\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = svm_model.predict(X_test_scaled)\n",
    "\n",
    "print(\"Previsões no conjunto de teste: \")\n",
    "print(y_pred[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8 - Treinamento de um modelo com Árvore de Decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previsões no conjunto de teste com Árvore de Decisão\n",
      "[1 0 0 0 0 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "print(\"Previsões no conjunto de teste com Árvore de Decisão\")\n",
    "print(y_pred_dt[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9 - Avaliação dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaliação do Modelo SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.83      0.80        99\n",
      "           1       0.65      0.56      0.60        55\n",
      "\n",
      "    accuracy                           0.73       154\n",
      "   macro avg       0.71      0.70      0.70       154\n",
      "weighted avg       0.73      0.73      0.73       154\n",
      "\n",
      "Avaliação do Modelo Árvore de Decisão: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.76      0.79        99\n",
      "           1       0.62      0.73      0.67        55\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.73      0.74      0.73       154\n",
      "weighted avg       0.76      0.75      0.75       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"Avaliação do Modelo SVM: \")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Avaliação do Modelo Árvore de Decisão: \")\n",
    "print(classification_report(y_test, y_pred_dt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 - Ajuste de Hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaliação do SVM com kernel 'linear':\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81        99\n",
      "           1       0.67      0.65      0.66        55\n",
      "\n",
      "    accuracy                           0.76       154\n",
      "   macro avg       0.74      0.74      0.74       154\n",
      "weighted avg       0.76      0.76      0.76       154\n",
      "\n",
      "Avaliação do SVM com kernel 'rbf':\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.83      0.80        99\n",
      "           1       0.65      0.56      0.60        55\n",
      "\n",
      "    accuracy                           0.73       154\n",
      "   macro avg       0.71      0.70      0.70       154\n",
      "weighted avg       0.73      0.73      0.73       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Hiperparâmetro SVM\n",
    "\n",
    "svm_model_linear = SVC(kernel='linear')\n",
    "svm_model_linear.fit(X_train_scaled, y_train)\n",
    "y_pred_linear = svm_model_linear.predict(X_test_scaled)\n",
    "\n",
    "svm_model_rbf = SVC(kernel='rbf')\n",
    "svm_model_rbf.fit(X_train_scaled, y_train)\n",
    "y_pred_rbf = svm_model_rbf.predict(X_test_scaled)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"Avaliação do SVM com kernel 'linear':\")\n",
    "print(classification_report(y_test, y_pred_linear))\n",
    "\n",
    "print(\"Avaliação do SVM com kernel 'rbf':\")\n",
    "print(classification_report(y_test, y_pred_rbf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaliação da Árvore de Decisão com max_depth=3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82        99\n",
      "           1       0.68      0.62      0.65        55\n",
      "\n",
      "    accuracy                           0.76       154\n",
      "   macro avg       0.74      0.73      0.73       154\n",
      "weighted avg       0.76      0.76      0.76       154\n",
      "\n",
      "Avaliação da Árvore de Decisão sem limite de profundidade:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.76      0.79        99\n",
      "           1       0.62      0.73      0.67        55\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.73      0.74      0.73       154\n",
      "weighted avg       0.76      0.75      0.75       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Hiperparâmetro Árvore de Decisão\n",
    "\n",
    "dt_model_depth3 = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "dt_model_depth3.fit(X_train, y_train)\n",
    "y_pred_depth3 = dt_model_depth3.predict(X_test)\n",
    "\n",
    "dt_model_no_limit = DecisionTreeClassifier(max_depth=None, random_state=42)\n",
    "dt_model_no_limit.fit(X_train, y_train)\n",
    "y_pred_no_limit = dt_model_no_limit.predict(X_test)\n",
    "\n",
    "print(\"Avaliação da Árvore de Decisão com max_depth=3:\")\n",
    "print(classification_report(y_test, y_pred_depth3))\n",
    "\n",
    "print(\"Avaliação da Árvore de Decisão sem limite de profundidade:\")\n",
    "print(classification_report(y_test, y_pred_no_limit))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11 - Relatório Final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análise Comparativa entre os Modelos SVM e Árvore de Decisão Desempenho\n",
    "\n",
    "    Com base nos resultados obtidos, os dois modelos apresentam características distintas, influenciando seu desempenho em diferentes contextos:\n",
    "\n",
    "    Modelo SVM (com kernel ajustado):\n",
    "\n",
    "    É altamente eficaz para conjuntos de dados bem estruturados e que não possuem uma quantidade excessiva de ruído.\n",
    "\n",
    "    O SVM tende a ter um F1-score mais elevado, indicando um equilíbrio mais consistente entre Precisão e Revocação.\n",
    "\n",
    "    A normalização dos dados contribuiu para o desempenho estável do modelo, evidenciado pela acurácia consistente, especialmente para o kernel 'rbf', que é ideal  \n",
    "    para dados com relações complexas.\n",
    "\n",
    "    Modelo Árvore de Decisão (com max_depth ajustado):\n",
    "\n",
    "    A Árvore de Decisão é intuitiva e interpretável, sendo fácil rastrear como as decisões foram tomadas.\n",
    "\n",
    "    Em termos de precisão geral, o modelo pode sofrer com overfitting em árvores muito profundas (sem restrição de max_depth), resultando em um desempenho inferior ao \n",
    "    SVM nos dados de teste.\n",
    "\n",
    "    Contudo, para dados menores ou mais simples, com alta linearidade, a Árvore de Decisão pode se apresentar como uma alternativa eficiente.\n",
    "\n",
    "    Critérios para a Escolha do Modelo Mais Adequado\n",
    "\n",
    "Desempenho Estatístico:\n",
    "\n",
    "Desempenho Geral\n",
    "SVM (kernel 'linear'):\n",
    "\n",
    "Acurácia: 76%\n",
    "F1-score: Maior equilíbrio geral para as duas classes, com 0.81 para a classe 0 e 0.66 para a classe 1.\n",
    "A alta precisão para a classe 0 (81%) sugere bom desempenho em identificar corretamente os negativos. No entanto, a revocação para a classe 1 é mais baixa (65%), mostrando que o modelo tem maior dificuldade em identificar verdadeiros positivos.\n",
    "\n",
    "SVM (kernel 'rbf'):\n",
    "\n",
    "Acurácia: 73%\n",
    "F1-score: Menor do que o kernel 'linear', especialmente para a classe 1 (0.60).\n",
    "Embora o kernel 'rbf' seja mais eficaz em modelar relações complexas, neste caso específico ele apresentou desempenho inferior ao kernel 'linear'.\n",
    "\n",
    "Árvore de Decisão (com max_depth=3):\n",
    "\n",
    "Acurácia: 76%\n",
    "F1-score: Muito próximo ao SVM com kernel 'linear', sendo 0.82 para a classe 0 e 0.65 para a classe 1.\n",
    "Limitar a profundidade da árvore evitou overfitting e manteve a consistência no desempenho.\n",
    "\n",
    "Árvore de Decisão (sem limite de profundidade):\n",
    "\n",
    "Acurácia: 75%\n",
    "F1-score: O resultado foi levemente inferior ao caso com max_depth=3, indicando que permitir maior profundidade resultou em possível overfitting, prejudicando a generalização.\n",
    "\n",
    "\n",
    "Interpretação e Tempo de Treinamento:\n",
    "\n",
    "Para aplicações em que a interpretabilidade é crucial, a Árvore de Decisão se torna mais vantajosa, permitindo que as regras do modelo sejam visualizadas.\n",
    "\n",
    "Além disso, a Árvore de Decisão é mais rápida para treinar, o que a torna uma boa opção para prototipagem rápida.\n",
    "\n",
    "Escalabilidade:\n",
    "\n",
    "O SVM pode ter dificuldades de escalabilidade em grandes conjuntos de dados, enquanto a Árvore de Decisão é mais escalável e se adapta melhor a grandes volumes de dados.\n",
    "\n",
    "Recomendação para Uso em Produção\n",
    "O modelo SVM seria o mais indicado para uso em produção em cenários onde:\n",
    "\n",
    "Há necessidade de maior precisão.\n",
    "Os dados são pré-processados adequadamente (normalizados).\n",
    "O desempenho do modelo com kernel ajustado (ex.: 'rbf') apresentou superioridade consistente nos testes.\n",
    "\n",
    "Por outro lado, o modelo Árvore de Decisão seria mais adequado em contextos onde:\n",
    "\n",
    "A interpretabilidade do modelo é uma prioridade.\n",
    "A escala e a velocidade de treinamento são considerações importantes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
